为了确保**众生谱 (StoryMap)** 项目能够稳定运行并具备完整的叙事分析能力，我为你整理了这份详尽的**需求与技术架构文档**。这份文档涵盖了我们目前实现的所有核心逻辑，你可以将其作为开发手册或作品集说明。

## ---

**📜 众生谱 (StoryMap) 需求规格说明书**

### **一、 项目愿景**

**众生谱**是一款基于大语言模型（LLM）的叙事资产管理工具，旨在帮助创作者、读者和游戏策划从海量文本中自动提取复杂的人物关系网，并实现多项目（卷宗）的持久化管理。

### ---

**二、 核心功能需求**

#### **1\. 秘档管理 (Project/Archive Management)**

* **多项目隔离**：支持新建、切换多个"秘档"（如《凡人修仙传》、《斗破苍穹》），不同秘档间的人物、关系数据物理隔离。  
* **本地持久化**：所有秘档及关联的关系网数据均存储于 SQLite 数据库（`storymap.db`），通过 FastAPI 后端提供 RESTful API 访问。  
* **数据过滤**：系统根据当前选中的秘档 ID，实时从数据库中筛选并渲染对应的关系图谱和表格。

#### **2\. 演化法阵 (AI Logic Arrays / Model Config)**

* **多协议适配**：支持 OpenAI 标准协议、火山方舟 (Volcano Engine) 以及阿里百炼 (Bailian) 三种主流 LLM 协议。  
* **多模型管理**：支持添加、编辑、删除多个 LLM 模型配置，每个配置包含独立的 API Key、Base URL 和 Model ID。  
* **自定义接口**：支持手动修改 BaseURL（适配代理/中转接口）和 Model ID，满足不同部署环境需求。  
* **模型测试**：内置连接测试功能，添加模型前可验证配置是否正确，避免推演时出错。  
* **默认模型**：支持设置默认模型，新建项目时自动使用默认配置。  
* **数据持久化**：所有模型配置存储于 SQLite 数据库，支持跨会话保存。

#### **3\. 智能解析 (Asynchronous AI Analysis)**

* **异步推演**：提交文本后，分析任务在后台运行，不阻塞用户操作界面。  
* **双渠道注入**：  
  * **手动粘贴**：直接在文本框内粘贴章节内容。  
  * **卷轴载入**：支持上传 .txt 文件，前端自动读取内容。  
* **任务监控**：右侧抽屉实时展示所有后台任务的进度百分比、运行状态（推演中/已完成/失败）。  
* **物理终止**：支持通过 AbortController 强行中断正在进行的网络请求，解决任务卡死问题。

#### **4\. 关系图谱与交互 (Visualization)**

* **动态渲染**：基于 G6 4.x 引擎，支持力导向布局和防闪烁重绘。  
* **势力识别**：节点颜色根据人物所属"势力/门派"动态映射。  
* **关系定义**：连线支持显示关系类型（如道侣、师徒、死敌），并以不同颜色和线型（实线/虚线）区分。

#### **5\. 数据安全 (Data Security & Logs)**

* **导入导出**：支持将当前秘档数据导出为标准的 .json 格式，并支持重新导入（导入时自动关联当前秘档）。  
* **实时日志**：系统记录每一步推演的详细轨迹（INFO/SUCCESS/ERROR），并支持一键导出 .txt 日志文件用于调试。

### ---

**三、 技术架构图**

| 模块 | 技术选型 | 说明 |
| :---- | :---- | :---- |
| **前端框架** | React \+ Vite | 轻量级响应式 UI，使用 Zustand 进行状态管理 |
| **状态管理** | Zustand | 跨组件同步任务进度与关系数据 |
| **后端框架** | FastAPI (Python) | 提供 RESTful API，处理 AI 推演与数据持久化 |
| **数据库** | SQLite 3 | 轻量级关系型数据库，存储项目、节点、关系数据 |
| **图形引擎** | AntV G6 4.x | 负责关系网的力导向布局与交互渲染 |
| **AI 通信** | OpenAI SDK | 支持 OpenAI 标准协议、阿里通义、火山方舟等多种 LLM 接口 |

### ---

**四、 关键数据模型 (SQLite Schema)**

#### **1\. 项目表 (projects)**

```sql
CREATE TABLE projects (
  id TEXT PRIMARY KEY,        -- 项目唯一标识，格式：proj_xxxxxx
  name TEXT NOT NULL          -- 项目名称（如"凡人修仙传"）
);
```

#### **2\. 节点表 (nodes)**

```sql
CREATE TABLE nodes (
  id TEXT NOT NULL,           -- 人物唯一标识
  label TEXT NOT NULL,        -- 人物姓名
  sect TEXT,                  -- 所属势力/门派
  project_id TEXT NOT NULL,   -- 关联的项目ID
  PRIMARY KEY (id, project_id)
);
```

#### **3\. 关系表 (edges)**

```sql
CREATE TABLE edges (
  id TEXT PRIMARY KEY,        -- 关系唯一标识，格式：edge_xxxxxxxx
  source TEXT NOT NULL,       -- 源节点ID
  target TEXT NOT NULL,       -- 目标节点ID
  label TEXT,                 -- 关系描述（如"师徒"、"道侣"）
  project_id TEXT NOT NULL    -- 关联的项目ID
);
```

#### **4\. LLM 模型表 (llm_models)**

```sql
CREATE TABLE llm_models (
  id TEXT PRIMARY KEY,        -- 模型配置唯一标识，格式：llm_xxxxxxxx
  name TEXT NOT NULL,         -- 模型显示名称（如"通义千问-Plus"）
  protocol TEXT NOT NULL,     -- 协议类型：openai/volcano/bailian
  api_key TEXT NOT NULL,      -- API 密钥
  base_url TEXT NOT NULL,     -- API 基础地址
  model_id TEXT NOT NULL,     -- 模型标识符（如"qwen-plus"）
  is_default INTEGER DEFAULT 0, -- 是否为默认模型（0/1）
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### **5\. API 数据格式**

前端与后端通过以下 JSON 格式交互：

**节点 (Node)**
```json
{
  "id": "unique_id",
  "label": "姓名",
  "sect": "所属势力",
  "project_id": "关联秘档ID"
}
```

**关系 (Edge)**
```json
{
  "id": "edge_xxxxxxxx",
  "source": "人物A_ID",
  "target": "人物B_ID",
  "label": "关系描述",
  "project_id": "关联秘档ID"
}
```

### ---

**五、 RESTful API 接口文档**

#### **基础路径**: `http://127.0.0.1:8000/api`

| 端点 | 方法 | 说明 | 请求体 | 响应 |
|------|------|------|--------|------|
| `/projects` | GET | 获取所有项目列表 | - | `[{id, name}, ...]` |
| `/projects` | POST | 创建新项目 | `{name: string}` | `{id, name}` |
| `/projects/{pid}/data` | GET | 获取项目的节点和关系 | - | `{nodes: [...], edges: [...]}` |
| `/projects/{pid}/analyze` | POST | 提交文本进行 AI 分析 | `{text, config, system_prompt}` | `{status, message?}` |
| `/projects/{pid}/export` | GET | 导出项目完整数据 | - | `{project, nodes, edges}` |
| `/projects/import` | POST | 导入项目数据 | `{project, nodes, edges}` | `{status, project_id}` |
| `/llm-models` | GET | 获取所有 LLM 模型配置 | - | `[{id, name, protocol, ...}, ...]` |
| `/llm-models` | POST | 添加新的 LLM 模型 | `{name, protocol, api_key, base_url, model_id, is_default}` | `{status, id}` |
| `/llm-models/{id}` | PUT | 更新 LLM 模型配置 | `{name, protocol, api_key, base_url, model_id, is_default}` | `{status}` |
| `/llm-models/{id}` | DELETE | 删除 LLM 模型配置 | - | `{status}` |
| `/llm-models/test` | POST | 测试 LLM 模型连接 | `{api_key, base_url, model_id, protocol}` | `{status, message, response?}` |
| `/llm-models/default` | GET | 获取默认 LLM 模型 | - | `{id, name, protocol, ...}` |

#### **LLM 配置格式 (config)**
```json
{
  "api_key": "your-api-key",
  "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
  "model": "qwen-plus"
}
```

#### **支持的协议类型**

| 协议 | 标识符 | 默认 Base URL | 说明 |
|------|--------|---------------|------|
| OpenAI | `openai` | `https://api.openai.com/v1` | 标准 OpenAI 协议，兼容大部分第三方接口 |
| 火山方舟 | `volcano` | `https://ark.cn-beijing.volces.com/api/v3` | 字节跳动火山引擎 |
| 阿里百炼 | `bailian` | `https://dashscope.aliyuncs.com/compatible-mode/v1` | 阿里云通义千问系列 |

### ---

**六、 开发者调试指南 (Debug Guide)**

1. **后端启动**：在项目根目录执行 `python backend/main.py`，服务将运行在 `http://127.0.0.1:8000`。  
2. **前端启动**：在 `frontend` 目录执行 `npm run dev`，访问 `http://localhost:5173`。  
3. **数据库检查**：使用 SQLite 客户端（如 DB Browser for SQLite）打开 `storymap.db` 查看数据。  
4. **API 测试**：使用 Postman 或 curl 测试后端接口，确保数据正确返回。  
5. **强制重置**：删除 `storymap.db` 文件并重启后端，数据库将自动重建。  
6. **CORS 问题**：后端已配置允许所有来源，如遇跨域问题请检查浏览器控制台。

### ---

**七、 项目架构总结**

```
众生谱 (StoryMap)
├── backend/
│   └── main.py              # FastAPI 后端服务，处理 AI 推演与数据持久化
├── frontend/
│   ├── src/
│   │   ├── App.jsx          # 主应用组件，项目管理与文本输入
│   │   ├── GraphView.jsx    # G6 关系图谱可视化组件
│   │   └── store.js         # Zustand 状态管理，API 调用逻辑
│   └── package.json         # 前端依赖配置
└── storymap.db              # SQLite 数据库文件（自动生成）
```

---

**下一步建议：**

1. **增强功能**：添加节点编辑、关系删除、势力颜色自定义等交互功能。  
2. **性能优化**：对大规模文本（>10万字）实现分块推演与进度条显示。  
3. **部署方案**：使用 Docker 容器化部署，或打包为 Tauri 桌面应用。  
4. **数据分析**：增加人物出场频率统计、关系强度计算等高级分析功能。  
5. **模型优化**：支持流式响应、温度参数调节、多轮对话上下文等高级 LLM 功能。
